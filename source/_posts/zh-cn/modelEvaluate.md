---
title: 如何评估 AI 模型的效果
date: 2024-08-14 20:50:31
updated:
keywords:
cover: /image/evaluate.png
top_image:
comments: false
maincolor:
categories:
  - ai 技术
tags:
  - 大模型
typora-root-url: ./modelEvaluate
---

# 1、概述

在工作中经常与 ai 模型算法同事打交道，有时他们推给我一个新模型或者优化的模型，我需要考虑如何评估它的效果，有没有达到我的业务要求。

借此机会，学习了一些评估 ai 模型效果的方式。

为了方便，下面提到的模型，如果没有特殊说明，都指的是 ai 模型。

模型有许多种分类，如大语言模型、检测模型、分类模型、预测模型等等，我们今天讨论的是检测模型给出的结果如何去评估。

# 2、模型输出的结果

> 用于评估分类模型性能的两个重要指标

## 2.1 准确率

指的是模型正确预测的样本数量与样本总体数量的比值。

> 准确率= 预测正确的样本数/样本总数

## 2.2 召回率

正例：输出结果达到阈值以上的样例

指的是模型预测的所有正样例中，预测正确的样例与正样例的比值

> 召回率 = 预测正确的正例数量/预测的正例总数

## 2.3 准确率召回率衡量的点

当阈值越高时，准确率肯定较高，但是召回率相对较低

当阈值较低，准确率会偏低，召回率相对变高

了解模型这两个率指标的数值，使准确率和召回率保持在相对平衡的状态下，得出需要设定的阈值。

有的场景要求准确率高，比如要求结果预测尽可能准确的医疗、法律研判，**需要有一个很确定的唯一值时**

有的场景要求召回率，比如检测出所有的垃圾邮件，检测所有的病毒等等，**需要得到一个结果集**

这两个指标都是越高越好，但是在实际应用中，往往需要在准确率和召回率之间进行权衡。例如，在某些情况下，我们可能更关心模型能找出所有正例（高召回率），即使这意味着模型会产生更多的假正例（低准确率）。在其他情况下，我们可能更希望模型只预测出高度可信的正例（高准确率），即使这意味着模型可能会错过一些真正的正例（低召回率）。

1. **看重召回率的场景**：假设我们正在开发一个用于检测疾病的医疗测试系统。在这种情况下，我们可能更看重召回率，因为我们希望找出所有可能的疾病病例，即使这意味着会有一些健康的人被误诊为病人（假正例）。因为漏诊（假负例）可能会对患者的健康产生严重影响。

2. **看重准确率的场景**：假设我们正在开发一个垃圾邮件过滤器。在这种情况下，我们可能更看重准确率，因为我们希望只有高度可信的垃圾邮件被过滤掉，即使这意味着可能会有一些垃圾邮件漏过过滤器（假负例）。因为误将重要邮件（假正例）过滤掉可能会对用户产生不便。
